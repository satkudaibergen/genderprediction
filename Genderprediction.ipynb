{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25d241d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 11ms/step - loss: 0.6916 - accuracy: 0.5066 - val_loss: 0.6805 - val_accuracy: 0.6974\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.6530 - val_loss: 0.6467 - val_accuracy: 0.7303\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.7878 - val_loss: 0.5339 - val_accuracy: 0.7829\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8289 - val_loss: 0.4694 - val_accuracy: 0.7763\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8750 - val_loss: 0.5060 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2355 - accuracy: 0.9030 - val_loss: 0.5480 - val_accuracy: 0.7566\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9145 - val_loss: 0.6194 - val_accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2150 - accuracy: 0.9079 - val_loss: 0.6335 - val_accuracy: 0.7697\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1986 - accuracy: 0.9161 - val_loss: 0.6649 - val_accuracy: 0.7368\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1930 - accuracy: 0.9145 - val_loss: 0.6795 - val_accuracy: 0.7368\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1781 - accuracy: 0.9276 - val_loss: 0.6747 - val_accuracy: 0.7632\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1831 - accuracy: 0.9178 - val_loss: 0.6944 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1787 - accuracy: 0.9145 - val_loss: 0.7083 - val_accuracy: 0.7368\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9211 - val_loss: 0.7205 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9260 - val_loss: 0.7520 - val_accuracy: 0.7368\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1665 - accuracy: 0.9211 - val_loss: 0.7502 - val_accuracy: 0.7434\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1601 - accuracy: 0.9178 - val_loss: 0.7529 - val_accuracy: 0.7368\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1583 - accuracy: 0.9194 - val_loss: 0.7596 - val_accuracy: 0.7368\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1427 - accuracy: 0.9243 - val_loss: 0.7832 - val_accuracy: 0.7434\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1520 - accuracy: 0.9211 - val_loss: 0.7958 - val_accuracy: 0.7368\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1511 - accuracy: 0.9227 - val_loss: 0.7814 - val_accuracy: 0.7434\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.9178 - val_loss: 0.7907 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9161 - val_loss: 0.8073 - val_accuracy: 0.7434\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9194 - val_loss: 0.8327 - val_accuracy: 0.7368\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1354 - accuracy: 0.9309 - val_loss: 0.8569 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9211 - val_loss: 0.8608 - val_accuracy: 0.7434\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9342 - val_loss: 0.8612 - val_accuracy: 0.7434\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9276 - val_loss: 0.8820 - val_accuracy: 0.7566\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9309 - val_loss: 0.9096 - val_accuracy: 0.7368\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9276 - val_loss: 0.9097 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9211 - val_loss: 0.9070 - val_accuracy: 0.7434\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1348 - accuracy: 0.9309 - val_loss: 0.9171 - val_accuracy: 0.7434\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9326 - val_loss: 0.9210 - val_accuracy: 0.7237\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.9112 - val_loss: 0.9040 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "\n",
    "# load the data\n",
    "df = pd.read_excel(\"C:/Users/satk8/Desktop/dataset.xlsx\",index_col=0)\n",
    "\n",
    "# preprocess the text data\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "# apply to dataframe\n",
    "df['Search Query'] = df['Search Query'].apply(preprocess)\n",
    "df['Clicked Result'] = df['Clicked Result'].apply(preprocess)\n",
    "\n",
    "# convert gender values to numerical\n",
    "df['Gender'] = df['Gender'].apply(lambda x: 1 if x.lower() == 'female' else 0)\n",
    "\n",
    "# convert the preprocessed text into numerical data using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Search Query'])\n",
    "X = X.toarray() # convert sparse matrix to dense array\n",
    "y = df['Gender'].values\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# define early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "# define a function to make predictions on user input\n",
    "def predict_gender(search_query):\n",
    "    search_query = preprocess(search_query)\n",
    "    new_data = [search_query]\n",
    "    new_data = vectorizer.transform(new_data)\n",
    "    new_data = new_data.toarray()\n",
    "    prediction = model.predict(new_data)[0][0]\n",
    "    if prediction > 0.5:\n",
    "        return \"female\"\n",
    "    else:\n",
    "        return \"male\"\n",
    "\n",
    "# define the GUI function\n",
    "def create_gui():\n",
    "    # create the main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Gender Prediction\")\n",
    "    \n",
    "    # define the labels and entry widgets\n",
    "    search_query_label = tk.Label(root, text=\"Enter a search query:\")\n",
    "    search_query_entry = tk.Entry(root, width=50)\n",
    "    prediction_label = tk.Label(root, text=\"\")\n",
    "    similar_words_label = tk.Label(root, text=\"\")\n",
    "    \n",
    "    # define the predict function\n",
    "    def predict():\n",
    "        # get the search query entered by the user\n",
    "        search_query = search_query_entry.get()\n",
    "\n",
    "        # preprocess the search query text\n",
    "        preprocessed_search_query = preprocess(search_query)\n",
    "\n",
    "        # convert the preprocessed text into numerical data using TfidfVectorizer\n",
    "        vectorized_search_query = vectorizer.transform([preprocessed_search_query]).toarray()\n",
    "\n",
    "        # make a prediction using the trained neural network\n",
    "        prediction = model.predict(vectorized_search_query)[0][0]\n",
    "\n",
    "        # convert the prediction to a binary label\n",
    "        binary_prediction = 1 if prediction > 0.5 else 0\n",
    "\n",
    "        # display the prediction result\n",
    "        if binary_prediction == 1:\n",
    "            prediction_label.config(text=\"The model predicted that the user who searched for '{}' is female ({}%).\".format(search_query, round(prediction * 100, 3)))\n",
    "        else:\n",
    "            prediction_label.config(text=\"The model predicted that the user who searched for '{}' is male ({}%).\".format(search_query, round((1 - prediction) * 100, 3)))\n",
    "\n",
    "        # get the similar words from the database\n",
    "        similar_words = df[df['Search Query'] == search_query]['Clicked Result'].values\n",
    "\n",
    "        # display the similar words\n",
    "        similar_words_label.config(text=\"Similar words: {}\".format(', '.join(similar_words)))\n",
    "    \n",
    "    # create a predict button\n",
    "    predict_button = tk.Button(root, text=\"Predict gender\", command=predict)\n",
    "    predict_button.pack()\n",
    "\n",
    "    # create a search query label and entry\n",
    "    search_query_label.pack()\n",
    "    search_query_entry.pack()\n",
    "\n",
    "    # create a prediction label\n",
    "    prediction_label.pack()\n",
    "\n",
    "    # create a similar words label\n",
    "    similar_words_label.pack()\n",
    "    \n",
    "    # bind the enter key to the predict function\n",
    "    search_query_entry.bind(\"<Return>\", predict)\n",
    "\n",
    "    # run the tkinter event loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de5790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
